---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About Me

Hi! Here is Wenxi Chen (陈文熙). I am a recent graduate from Shanghai Jiao Tong University (SJTU), where I earned my Bachelor's degree in Computer Science (IEEE pilot class).  Since 2023, I have been working as a research intern at the [X-Lance Lab](https://x-lance.sjtu.edu.cn) at SJTU, under the supervision of Prof. [Xie Chen](https://chenxie95.github.io/).


I'm generally interested in understanding & generation in speech and audio, as well as multimodal large language models. My previous projects have involved audio self-supervised learning, audio scene classification, audio captioning and end-to-end spoken dialogue models. 


<!-- ## Recent News

* *June 2023*: Joining the [SCALE 2023 Workshop](https://hltcoe.jhu.edu/research/scale/scale-2023) at John's Hopkins University
* *June 2022*: Joining the [JSALT 2022 Workshop](https://www.clsp.jhu.edu/2022-eighth-frederick-jelinek-memorial-summer-workshop/) at John's Hopkins University
* *May 2021*: Interning at [Dr. Dong Yu's](https://sites.google.com/view/dongyu888/) AI lab at Tencent America -->

## Selected Publications

For the most up-to-date information, please visit my [Google Scholar](https://scholar.google.com/citations?user=7YPoSY0AAAAJ&hl=en) profile.  
(* indicates equal contribution)


<!-- *Speech Translation* -->
**SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation**\
<sub>Keqi Deng, **Wenxi Chen**, Xie Chen, Phil Woodland</sub>\
<sub>*ACL 2025*</sub>\
<sub>[paper](https://arxiv.org/abs/2504.15509)</sub>


**SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training**\
<sub>**Wenxi Chen**, Ziyang Ma, Ruiqi Yan, Yuzhe Liang, Xiquan Li, Ruiyang Xu, Zhikang Niu, Yanqiao Zhu, Yifan Yang, Zhanxun Liu, Kai Yu, Yuxuan Hu, Jinyu Li, Yan Lu, Shujie Liu, Xie Chen</sub>\
<sub>*ACL 2025 (Findings)*</sub>\
<sub>[paper](https://arxiv.org/abs/2412.15649) / [demo](https://slam-omni.github.io/) / [code](https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/s2s)</sub>


**SLAM-AAC: Enhancing Audio Captioning with Paraphrasing Augmentation and CLAP-Refine through LLMs**\
<sub>**Wenxi Chen\***, Ziyang Ma\*, Xiquan Li, Xuenan Xu, Yuzhe Liang, Zhisheng Zheng, Kai Yu, Xie Chen</sub>\
<sub>*ICASSP 2025*</sub>\
<sub>[paper](https://arxiv.org/abs/2410.09503) / [code](https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/slam_aac)</sub>
<!-- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/slam-aac-enhancing-audio-captioning-with/audio-captioning-on-audiocaps)](https://paperswithcode.com/sota/audio-captioning-on-audiocaps?p=slam-aac-enhancing-audio-captioning-with)  [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/slam-aac-enhancing-audio-captioning-with/audio-captioning-on-clotho)](https://paperswithcode.com/sota/audio-captioning-on-clotho?p=slam-aac-enhancing-audio-captioning-with)\ -->

**DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning**\
<sub>Xiquan Li, **Wenxi Chen**, Ziyang Ma, Xuenan Xu, Yuzhe Liang, Zhisheng Zheng, Qiuqiang Kong, Xie Chen</sub>\
<sub>*ICASSP 2025 (oral)*</sub>\
<sub>[paper](https://arxiv.org/abs/2410.09472) / [code](https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac)</sub>

<!-- **EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark**  
<sub>Ziyang Ma, Mingjie Chen, Hezhao Zhang, Zhisheng Zheng, **Wenxi Chen**, Xiquan Li, Jiaxin Ye, Xie Chen, Thomas Hain</sub>\
<sub>*Interspeech 2024 (oral)*</sub>\
<sub>[paper](https://www.isca-archive.org/interspeech_2024/ma24b_interspeech.pdf) / [code](https://github.com/emo-box/EmoBox)</sub> -->

**EAT: Self-Supervised Pre-Training with Efficient Audio Transformer**\
<sub>**Wenxi Chen**, Yuzhe Liang, Ziyang Ma, Zhisheng Zheng, Xie Chen</sub>\
<sub>*IJCAI 2024*</sub>\
<sub>[paper](https://www.ijcai.org/proceedings/2024/0421.pdf) / [code](https://github.com/cwx-worst-one/EAT)</sub>
<!-- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eat-self-supervised-pre-training-with/audio-classification-on-balanced-audio-set)](https://paperswithcode.com/sota/audio-classification-on-balanced-audio-set?p=eat-self-supervised-pre-training-with)\ -->


<!-- ***

*Multilingual Speech Recognition*

**Improving Massively Multilingual ASR With Auxiliary CTC Objectives**\
<sub>William Chen, **Brian Yan**, Jiatong Shi, Yifan Peng, Soumi Maiti, Shinji Watanabe</sub>\
<sub>*2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023*</sub>\
<sub>[paper](https://arxiv.org/abs/2302.12829)</sub>

*** -->


## Activities

### Experience
Research Intern @ [Microsoft Research Asia (MSRA)](https://www.msra.cn/)  
General Artificial Intelligence Group & Speech Team, Beijing, China  
Co-advised by Dr. [Shujie Liu](https://www.microsoft.com/en-us/research/people/shujliu/) & Dr. [Jinyu Li](https://www.microsoft.com/en-us/research/people/jinyli/)
<sub>*2024.09-2025.06*</sub>  


### Competition

[IEEE ICME 2024 Challenge Semi-supervised Acoustic Scene Classification under Domain Shift](https://ascchallenge.xshengyun.com/)  
<sub>*Ranked 2nd, Team Leader*</sub>

[DCASE Challenge 2024 Task 6: Automated Audio Captioning](https://dcase.community/challenge2024/task-automated-audio-captioning-results)  
<sub>*Ranked 3rd, Team Leader*</sub>

<!-- ***

*Academic Service*

Reviewer\
<sub>ICASSP, Interspeech, ASRU, EMNLP, NAACL, APSIPA, SLT</sub> -->


### Awards
Rongchang Science and Technology Innovation Scholarship, 2024


## CV
Here is my [CV](../assets/pdf/CV_陈文熙.pdf) (Chinese).


## Contact

Email: <a href="mailto:1029713857@sjtu.edu.cn">1029713857@sjtu.edu.cn</a>